{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standard datasets are used to train natural language models... when crunched by a model, the output reflects quirks in the algorithm rather then the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories =['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print twenty_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.graphics',\n",
       " 'soc.religion.christian',\n",
       " 'soc.religion.christian',\n",
       " 'soc.religion.christian',\n",
       " 'soc.religion.christian',\n",
       " 'soc.religion.christian',\n",
       " 'sci.med',\n",
       " 'sci.med',\n",
       " 'sci.med']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[twenty_train.target_names[t] for t in twenty_train.target[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english', min_df = 3, lowercase=True, ngram_range=(1,2))\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "#min_df - a word has to occur in (x) documents to be considered a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'say say', 24934),\n",
       " (u'woods', 30960),\n",
       " (u'mdbs', 18117),\n",
       " (u've thinking', 30041),\n",
       " (u'atheist posting', 3391),\n",
       " (u'things things', 28177),\n",
       " (u'usenet', 29742),\n",
       " (u'biochemistry chairman', 4295),\n",
       " (u'registered dietician', 23649),\n",
       " (u'dna', 9017)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.items()[:10]\n",
    "#this is a dictionary so it has .items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31594"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x31594 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 65 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because text data is high dimensional and sparse, a given word probably doesn't exist in a given document\n",
    "\n",
    "NB about sparse matricies: doesn't store 0s, just saves value and location and assumes everything else is 0\n",
    "**occasionally this fails and the algorithm doen't play well with sparse matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF*IDF = Term frequency* inverse document frequency\n",
    "term frequency = frequency of a word in a given document \n",
    "inverse document frequency = percent of documents the word occurs in \n",
    "\n",
    "gives higher weights to infrequently occuring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "#model... like clf\n",
    "X_train_tfidf = transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 29187)\t0.122184682794\n",
      "  (0, 28033)\t0.0833703282547\n",
      "  (0, 13087)\t0.127476183175\n",
      "  (0, 10172)\t0.127476183175\n",
      "  (0, 28022)\t0.127476183175\n",
      "  (0, 12793)\t0.118080276228\n",
      "  (0, 16106)\t0.113254460724\n",
      "  (0, 9115)\t0.0830937280025\n",
      "  (0, 16891)\t0.0828212256827\n",
      "  (0, 29465)\t0.0704820569062\n",
      "  (0, 6072)\t0.25495236635\n",
      "  (0, 20365)\t0.127476183175\n",
      "  (0, 21979)\t0.0398304739967\n",
      "  (0, 19652)\t0.0398304739967\n",
      "  (0, 29198)\t0.120018232264\n",
      "  (0, 1785)\t0.074142400285\n",
      "  (0, 11307)\t0.0729975420101\n",
      "  (0, 17257)\t0.120018232264\n",
      "  (0, 1449)\t0.118080276228\n",
      "  (0, 1169)\t0.269868268172\n",
      "  (0, 27843)\t0.0945193296801\n",
      "  (0, 29391)\t0.101977280591\n",
      "  (0, 6793)\t0.0543905896741\n",
      "  (0, 22485)\t0.0930470585213\n",
      "  (0, 2136)\t0.0751838238838\n",
      "  :\t:\n",
      "  (2256, 13344)\t0.0648682824133\n",
      "  (2256, 5110)\t0.066938392534\n",
      "  (2256, 16298)\t0.0606666781161\n",
      "  (2256, 17646)\t0.054633401601\n",
      "  (2256, 25146)\t0.0555599161106\n",
      "  (2256, 10638)\t0.0473951454191\n",
      "  (2256, 10627)\t0.0648682824133\n",
      "  (2256, 4114)\t0.137281116323\n",
      "  (2256, 4112)\t0.200815177602\n",
      "  (2256, 17706)\t0.047320745595\n",
      "  (2256, 11041)\t0.0604677243453\n",
      "  (2256, 26689)\t0.161300115476\n",
      "  (2256, 31155)\t0.0213166536921\n",
      "  (2256, 3106)\t0.0236097486634\n",
      "  (2256, 6402)\t0.0513258910299\n",
      "  (2256, 27853)\t0.0440451021314\n",
      "  (2256, 29059)\t0.060271675113\n",
      "  (2256, 4003)\t0.0365050549591\n",
      "  (2256, 9761)\t0.0359596376396\n",
      "  (2256, 16891)\t0.0604677243453\n",
      "  (2256, 6793)\t0.0397105350262\n",
      "  (2256, 294)\t0.0476969364096\n",
      "  (2256, 16877)\t0.0134827670812\n",
      "  (2256, 20340)\t0.0142002207983\n",
      "  (2256, 26932)\t0.0134291339036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor key in count_vect.vocabulary_:\\n    reversed_vocab[count_vect.vocabulary_[key]] = key    \\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X_train_tfidf\n",
    "#prints the location in the sparse matrix and the tfidf score\n",
    "reversed_vocab = dict()\n",
    "reversed_vocab = {v:k for (k,v) in count_vect.vocabulary_.items()}\n",
    "\"\"\"\n",
    "for key in count_vect.vocabulary_:\n",
    "    reversed_vocab[count_vect.vocabulary_[key]] = key    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstatistically you would want to normalize word counts \\nbetween 0 and 1 but in practice TFIDF is a useful because gives\\ndifferent weight to rare terms\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\"\"\"\n",
    "statistically you would want to normalize word counts \n",
    "between 0 and 1 but in practice TFIDF is a useful because gives\n",
    "different weight to rare terms\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80212483  0.82735724  0.76298269]\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf_dense = X_train_tfidf.toarray()\n",
    "tree = DecisionTreeClassifier()\n",
    "print cross_val_score(tree, X_train_tfidf_dense, twenty_train.target, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87250996,  0.86719788,  0.84553928])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 10)\n",
    "cross_val_score(forest, X_train_tfidf_dense, twenty_train.target, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95575221,  0.97123894,  0.9579646 ,  0.96238938,  0.96659243])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "cross_val_score(logreg,X_train_tfidf, twenty_train.target, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96017699,  0.96902655,  0.96460177,  0.95575221,  0.9688196 ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "cross_val_score(nb,X_train_tfidf, twenty_train.target, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train_tfidf_dense, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.81458819e-03,   9.44967792e-05,   1.28493909e-04, ...,\n",
       "         5.72509123e-04,   2.25088761e-04,   1.80271434e-04])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x>0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
