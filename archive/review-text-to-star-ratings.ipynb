{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Standard datasets are used to train natural language models... when crunched by a model, the output reflects quirks in the algorithm rather then the data.\"\n",
    "\n",
    "This notebook contains feature extraction, weighting, and modeling portions of the drug-review-text-to-star-rating prediction project. Other aspects of the process--e.g., scraping, cleaning, or visualizing the data--are not included here. Furthermore, there are many possible directions this project can go (re: feature/model selection, weighting, etc.); this is but a starting place. Plus it only looks at \"satisfaction\" ratings for now.\n",
    "\n",
    "Feature extraction is handled by sklearn's CountVectorizer function. For now, we're using it to tokenize our review text data into unigrams (words) and bigrams (pairs of words). These fatures are then weighted by tf-idf scores (term frequency-inverse document frequency, so a token that shows up in a lot of documents isn't given much weight, but an otherwise rare token showing up many times in the same document is heavily weighted).\n",
    "\n",
    "We then pass the features into a couple different classifier models and see how they perform.\n",
    "\n",
    "```\n",
    "QUESTIONS/TODO:\n",
    "    Why use CountVectorizer if we're going to be using tfidf? sklearn has a TfIdfVectorizer function.\n",
    "    How is performance measured? What is that cross validation metric that's being spewed out? Is it accuracy?\n",
    "    How to use a regression model instead of classifiers?\n",
    "    Use non-deprecated modules instead of cross_validation.\n",
    "    How should models be evaluated? Accuracy alone isn't necessarily the best; should explore the data first and see\n",
    "        how skewed it is towards any given star rating. Also try precision/recall/F1.          \n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell just sets up some data to use.\n",
    "import pickle\n",
    "\n",
    "with open('abilify.p', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "reviews = [datum['comment'] for datum in data]\n",
    "satisfaction_ratings = [datum['satisfaction'] for datum in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'drugName': 'abilify', 'site': 'webMD', 'condition': 'Additional Medications to Treat Depression', 'reviewDate': '10/15/2017', 'userName': 'caner1', 'ageRange': '65-74', 'gender': 'Female', 'role': 'Patient', 'medDuration': '1 to 6 months', 'effectiveness': 2, 'ease_of_use': 3, 'satisfaction': 1, 'genRating': None, 'comment': 'Terrible made me clench my teeth and rock back & forth. Two yrs later I still do it. Terrible side effects for me. not recommended by me.', 'upVotes': 2}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Terrible made me clench my teeth and rock back & forth. Two yrs later I still do it. Terrible side effects for me. not recommended by me.',\n",
       " \"I was put on abilify for depression along with Lexapro.  At first there was no side affects.  Then after about 2 years I gained about 90 pounds.  Also my right hand began to shake.  But the worst thing was not being able to control my bowel movements.  The thing is I did not realize it was the abilify causing these problems.  The way I figured out the cause was I ran out of abilify and was off it for about a week.  I started regaining control of my bowels (this is one thing they don't list as a side affect).  That had to be the most embarrassing period of my life.  Since I quit taking the drug I lost 80 pounds and my hand stopped shaking.  But best of all I have control of my bowels.  They say the drug has different affects on people but it's not the drug for me.  To those that it helped I say hurrah but I've read more negative comments than positive.\",\n",
       " \"I have suffered with chronic depression for most of my life. I have tried almost every antidepressant out there with varying degrees of success. I currently take 90 mgs of Cymbalta every day. While it is somewhat effective for me I still suffered greatly from nagging depression. It wasn't until my psychiatrist added Abilify that I experienced almost complete relief of my depression. Within two weeks I was feeling better than I have in many years. The feelings of sadness are gone and I wake up feeling ready to face the day. It has helped me tremendously. For me, this drug has worked miracles I never thought possible. \",\n",
       " 'This medication (as an add on to Citalopram) makes me want to get up early every day and be productive.  I feel happier than I ever thought possible with the addition of this med (having dealt with minor chronic depression for most of my adult life).',\n",
       " 'I used to be extremely impatient, irritable and had frequent anger bursts.\\nAfter I started Abilify 5mg together with Bupropion 300mg I radically changed. Now I am extremely patient, but I miss my old self as a go-getter. Anyway my family is thankful I am under treatment so I can manage my life more wisely.',\n",
       " 'adding this to my treatment helped me greatly.',\n",
       " 'Stay tired all the time. Drool. ',\n",
       " 'When I took the medication, after a few months, I turned bright red like a pickled beet and I had a heart rate of about 200.  Overall, it almost killed me.',\n",
       " 'Lifesaver for me.',\n",
       " 'It is effective but I have gained weight with it and want to get off of it.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 5, 5, 5, 5, 1, 1, 5, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satisfaction_ratings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english', min_df = 2, lowercase=True, ngram_range=(1,2))\n",
    "X_train_counts = count_vect.fit_transform(reviews)\n",
    "#min_df - a word has to occur in (x) documents to be considered a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2831"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2831 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 65 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because text data is high dimensional and sparse, a given word probably doesn't exist in a given document\n",
    "\n",
    "NB about sparse matricies: doesn't store 0s, just saves value and location and assumes everything else is 0\n",
    "**occasionally this fails and the algorithm doen't play well with sparse matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "X_train_tfidf = transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF = Term frequency times inverse document frequency\n",
    "\n",
    "term frequency = frequency of a word in a given document \n",
    "\n",
    "inverse document frequency = percent of documents the word occurs in \n",
    "\n",
    "gives higher weights to infrequently occuring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2465)\t0.648544967256\n",
      "  (0, 2818)\t0.324272483628\n",
      "  (0, 1475)\t0.319461115508\n",
      "  (0, 920)\t0.188646037496\n",
      "  (0, 2071)\t0.400795196495\n",
      "  (0, 2819)\t0.419472598021\n",
      "  (1, 139)\t0.120911521184\n",
      "  (1, 694)\t0.04734921795\n",
      "  (1, 1508)\t0.0926364780062\n",
      "  (1, 269)\t0.224565730471\n",
      "  (1, 2792)\t0.0606429065346\n",
      "  (1, 1140)\t0.0662752751989\n",
      "  (1, 133)\t0.117545127139\n",
      "  (1, 1958)\t0.160055106797\n",
      "  (1, 2121)\t0.0838451765612\n",
      "  (1, 1230)\t0.212518205619\n",
      "  (1, 396)\t0.0977690865135\n",
      "  (1, 2191)\t0.129262897828\n",
      "  (1, 2775)\t0.101586709676\n",
      "  (1, 2476)\t0.267837210652\n",
      "  (1, 209)\t0.0850772352367\n",
      "  (1, 581)\t0.296897772178\n",
      "  (1, 1784)\t0.112282865236\n",
      "  (1, 748)\t0.0718725675552\n",
      "  (1, 2047)\t0.124590504694\n",
      "  :\t:\n",
      "  (704, 452)\t0.120529340715\n",
      "  (704, 1778)\t0.134237160689\n",
      "  (704, 733)\t0.12877124694\n",
      "  (704, 1622)\t0.141283949118\n",
      "  (704, 734)\t0.145749925833\n",
      "  (704, 2829)\t0.12877124694\n",
      "  (704, 19)\t0.151215839582\n",
      "  (704, 385)\t0.141283949118\n",
      "  (704, 201)\t0.158262628011\n",
      "  (704, 1164)\t0.158262628011\n",
      "  (704, 499)\t0.158262628011\n",
      "  (704, 1304)\t0.137508019608\n",
      "  (704, 2113)\t0.145749925833\n",
      "  (704, 356)\t0.158262628011\n",
      "  (704, 563)\t0.145749925833\n",
      "  (704, 198)\t0.145749925833\n",
      "  (704, 1903)\t0.158262628011\n",
      "  (704, 692)\t0.151215839582\n",
      "  (704, 2710)\t0.151215839582\n",
      "  (704, 509)\t0.145749925833\n",
      "  (704, 2088)\t0.151215839582\n",
      "  (704, 2433)\t0.151215839582\n",
      "  (704, 2721)\t0.158262628011\n",
      "  (704, 1647)\t0.151215839582\n",
      "  (704, 2000)\t0.158262628011\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf)\n",
    "#prints the location in the sparse matrix and the tfidf score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comra_000\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nstatistically you would want to normalize word counts \\nbetween 0 and 1 but in practice TFIDF is a useful because gives\\ndifferent weight to rare terms\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Refactor to use model_selection module\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_dense = X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32167832,  0.34507042,  0.40140845,  0.32857143,  0.27536232])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "cross_val_score(tree, X_train_tfidf_dense, satisfaction_ratings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36363636,  0.34507042,  0.40140845,  0.29285714,  0.2826087 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 10)\n",
    "cross_val_score(tree, X_train_tfidf_dense, satisfaction_ratings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34265734,  0.40140845,  0.3943662 ,  0.30714286,  0.30434783])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "cross_val_score(tree, X_train_tfidf_dense, satisfaction_ratings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35664336,  0.36619718,  0.40140845,  0.33571429,  0.25362319])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "cross_val_score(tree, X_train_tfidf_dense, satisfaction_ratings, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not so great, but at least they're better than what we would expect by sheer guessing (0.20, or 1/5, picking a random star). Values above represent the average accuracy (I think?) of each test run when trained on a subset of the dataset: see https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
